{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data set\n",
    "\n",
    "dataset = pd.read_csv(\"C:/Users/Mohil/Documents/Quarter 2/CS 613/spambase.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomizing the data set\n",
    "\n",
    "data = dataset.iloc[:,:].values\n",
    "d = len(dataset.iloc[0,:].values)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "x = data[:,:d-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarize the feature vector using mean\n",
    "\n",
    "mean = np.mean(x, axis=0)\n",
    "\n",
    "for i in range(0, x.shape[1]):\n",
    "    for j in range(0, x.shape[0]): \n",
    "        if(x[j][i]>=mean[i]):\n",
    "            x[j][i]=1\n",
    "        else:\n",
    "            x[j][i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset            \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the overall entropy\n",
    "\n",
    "def entropy(k, pn, p, n):\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(k):\n",
    "        pi = pn[i][0]\n",
    "        ni = pn[i][1]\n",
    "        sum += ((pi+ni)/(p+n)) * initial_entropy(pi/(pi+ni), ni/(pi+ni))\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the initial entropy\n",
    "\n",
    "def initial_entropy(p, n):\n",
    "    \n",
    "    a = (-p/(p+n))*np.log2(p/(p+n))\n",
    "    b = (-n/(p+n))*np.log2(n/(p+n))\n",
    "    if np.isnan(a):\n",
    "        a = 0\n",
    "    if np.isnan(b):\n",
    "        b = 0\n",
    "\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the information gain\n",
    "\n",
    "def gain(feature, y, p, n):\n",
    "\n",
    "   \n",
    "    unique_values = np.unique(feature)\n",
    "    k = len(unique_values)\n",
    "    pn = []\n",
    "    for val in unique_values:\n",
    "        pi = 0\n",
    "        ni = 0\n",
    "        for i, item in enumerate(feature):\n",
    "            \n",
    "            if item == val:\n",
    "                if y[i] == 1:\n",
    "                    pi +=1\n",
    "                else:\n",
    "                    ni +=1\n",
    "        pn.append([pi,ni])\n",
    "\n",
    "    return overall_entropy(p,n) - entropy(k, pn, p, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the best splitting attribute\n",
    "\n",
    "def find_best_split(columns, y_val, p, n, done = [-1]):\n",
    "\n",
    "    igs = []\n",
    "    for i in range(columns.shape[1]):\n",
    "        if i not in done:\n",
    "            \n",
    "            igs.append([i, gain(columns[:,i], y_val, p, n)])\n",
    "    \n",
    "    return sorted(igs, key = lambda x: x[1], reverse= True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to traverse a tree\n",
    "\n",
    "def pretty_print_tree(root):\n",
    "    stack = []\n",
    "    rules = set()\n",
    "\n",
    "    def traverse(node, stack, rules):\n",
    "        if 'label' in node:\n",
    "            stack.append(' THEN ' + str(node['label']))\n",
    "            rules.add(''.join(stack))\n",
    "            stack.pop()\n",
    "        elif 'feature' in node:\n",
    "            ifnd = 'IF ' if not stack else ' AND '\n",
    "            stack.append(ifnd + str(node['feature']) + ' EQUALS ')\n",
    "            for subnode_key in node['sub_nodes']:\n",
    "                stack.append(str(subnode_key))\n",
    "                traverse(node['sub_nodes'][subnode_key], stack, rules)\n",
    "                stack.pop()\n",
    "            stack.pop()\n",
    "\n",
    "    traverse(root, stack, rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict the values\n",
    "\n",
    "def predict(tree, row):\n",
    "\n",
    "    if \"label\" in tree:\n",
    "        y_pred.append(tree[\"label\"])\n",
    "        return y_pred\n",
    "    \n",
    "    elif 'feature' in tree:\n",
    "        sub_nodes = tree[\"sub_nodes\"]\n",
    "        root_feature_id = tree[\"feature\"]\n",
    "\n",
    "        predict(tree[\"sub_nodes\"][row[root_feature_id]], row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to construct a decsion tree\n",
    "\n",
    "used_features = []\n",
    "tree = {}\n",
    "\n",
    "\n",
    "def decision_tree(data, spam, non_spam):\n",
    "   \n",
    "    root = {}\n",
    "    counter = Counter()\n",
    "    target =  data[:, data.shape[1]-1]\n",
    "    for y_val in target:\n",
    "        counter[y_val] +=1\n",
    "    \n",
    "    if (len(counter) == 1):\n",
    "        root[\"label\"] = counter.most_common(1)[0][0]\n",
    "        return root\n",
    "    \n",
    "    if len(used_features) == data.shape[1]-1:\n",
    "        root[\"label\"] = counter.most_common(1)[0][0]\n",
    "        return root\n",
    "    \n",
    "    else:\n",
    "       \n",
    "        no_target = data[:, :data.shape[1]-1]\n",
    "        best_feature_id = find_best_split(no_target, target, spam,non_spam, used_features)\n",
    "        used_features.append(best_feature_id)\n",
    "       \n",
    "        root[\"feature\"] = best_feature_id\n",
    "        root[\"sub_nodes\"] = {}\n",
    "        x_values = set()\n",
    "        x_values.update(data[:, best_feature_id])\n",
    "        \n",
    "        for x_value in x_values:\n",
    "            \n",
    "            counter = Counter()\n",
    "            \n",
    "            tmp = data[data[:, best_feature_id] == x_value]\n",
    "           \n",
    "            if len(tmp) == 0:\n",
    "                for y_val in tmp[:, tmp.shape[1] - 1]:\n",
    "                    counter[y_val] += 1\n",
    "                root[\"sub_nodes\"][x_value] = {\"leaf\": counter.most_common(1)[0][0]}\n",
    "           \n",
    "            else:\n",
    "                #recurrsion\n",
    "                root[\"sub_nodes\"][x_value] = decision_tree(tmp, spam, non_spam)\n",
    "        return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the feature values into spam and not spam classes\n",
    "\n",
    "x_spam = []\n",
    "x_notspam = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    \n",
    "    if y_train[i] == 1:\n",
    "        x_spam.append(x_train[i])\n",
    "   \n",
    "    else:\n",
    "        x_notspam.append(x_train[i])\n",
    "        \n",
    "x_spam = np.array(x_spam)\n",
    "x_notspam =np.array(x_notspam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log2\n",
      "  \"\"\"\n",
      "C:\\Users\\Mohil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#constructing a tree using training data set\n",
    "\n",
    "data_set = np.append(x_train, np.array(y_train).reshape(len(y_train),1), axis=1)\n",
    "tree = decision_tree(data_set, len(x_spam), len(x_notspam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature': 52, 'sub_nodes': {0.0: {'feature': 6, 'sub_nodes': {0.0: {'feature': 51, 'sub_nodes': {0.0: {'feature': 25, 'sub_nodes': {0.0: {'feature': 22, 'sub_nodes': {0.0: {'feature': 15, 'sub_nodes': {0.0: {'feature': 23, 'sub_nodes': {0.0: {'feature': 26, 'sub_nodes': {0.0: {'feature': 21, 'sub_nodes': {0.0: {'feature': 27, 'sub_nodes': {0.0: {'feature': 45, 'sub_nodes': {0.0: {'feature': 18, 'sub_nodes': {0.0: {'feature': 19, 'sub_nodes': {0.0: {'feature': 33, 'sub_nodes': {0.0: {'feature': 36, 'sub_nodes': {0.0: {'feature': 41, 'sub_nodes': {0.0: {'feature': 43, 'sub_nodes': {0.0: {'feature': 0, 'sub_nodes': {0.0: {'feature': 8, 'sub_nodes': {0.0: {'feature': 10, 'sub_nodes': {0.0: {'feature': 20, 'sub_nodes': {0.0: {'feature': 44, 'sub_nodes': {0.0: {'feature': 5, 'sub_nodes': {0.0: {'feature': 28, 'sub_nodes': {0.0: {'feature': 38, 'sub_nodes': {0.0: {'feature': 11, 'sub_nodes': {0.0: {'feature': 1, 'sub_nodes': {0.0: {'feature': 49, 'sub_nodes': {0.0: {'feature': 24, 'sub_nodes': {0.0: {'feature': 4, 'sub_nodes': {0.0: {'feature': 32, 'sub_nodes': {0.0: {'feature': 50, 'sub_nodes': {0.0: {'feature': 13, 'sub_nodes': {0.0: {'feature': 54, 'sub_nodes': {0.0: {'feature': 48, 'sub_nodes': {0.0: {'feature': 2, 'sub_nodes': {0.0: {'feature': 12, 'sub_nodes': {0.0: {'feature': 30, 'sub_nodes': {0.0: {'feature': 34, 'sub_nodes': {0.0: {'feature': 35, 'sub_nodes': {0.0: {'feature': 39, 'sub_nodes': {0.0: {'feature': 40, 'sub_nodes': {0.0: {'feature': 3, 'sub_nodes': {0.0: {'feature': 7, 'sub_nodes': {0.0: {'feature': 9, 'sub_nodes': {0.0: {'feature': 14, 'sub_nodes': {0.0: {'feature': 16, 'sub_nodes': {0.0: {'feature': 17, 'sub_nodes': {0.0: {'feature': 29, 'sub_nodes': {0.0: {'feature': 31, 'sub_nodes': {0.0: {'feature': 37, 'sub_nodes': {0.0: {'feature': 42, 'sub_nodes': {0.0: {'feature': 46, 'sub_nodes': {0.0: {'feature': 47, 'sub_nodes': {0.0: {'feature': 53, 'sub_nodes': {0.0: {'feature': 55, 'sub_nodes': {0.0: {'feature': 56, 'sub_nodes': {0.0: {'label': 0.0}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 1.0}}}, 1.0: {'label': 1.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 1.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 1.0}}}, 1.0: {'label': 0.0}}}, 1.0: {'label': 1.0}}}, 1.0: {'label': 1.0}}}, 1.0: {'label': 1.0}}}\n",
      "0.7915451895043731 0.8729903536977492 0.8302752293577983 0.8520208604954368\n"
     ]
    }
   ],
   "source": [
    "#calculate the statistics\n",
    "y_pred = []\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "a = 0\n",
    "values =[600, 616, 840, 1034, 1167]\n",
    "\n",
    "for i in range(0,len(y_test)):\n",
    "    \n",
    "    if not i in values:\n",
    "        \n",
    "        sample = x_test[i,:]\n",
    "        y_pred.clear()\n",
    "        predict(tree, sample)\n",
    "\n",
    "        if(y_pred[0] == 1 and y_test[i] == 1):\n",
    "            tp = tp+1\n",
    "        if(y_pred[0] == 1 and y_test[i] == 0):\n",
    "            fp = fp +1\n",
    "        if(y_pred[0] == 0 and y_test[i] == 0):\n",
    "            tn = tn+1\n",
    "        if(y_pred[0] == 0 and y_test[i] == 1):\n",
    "            fn = fn+1\n",
    "        if(y_pred[0]==y_test[i]):\n",
    "            a = a+1\n",
    "        \n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*precision*recall/(precision+ recall)\n",
    "accuracy = a/len(y_test)\n",
    "\n",
    "print(tree)\n",
    "print(precision,recall,f1,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
